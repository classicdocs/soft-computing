{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = np.ones((3,3))\n",
    "\n",
    "def image_gray(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def image_bin(image_gs):\n",
    "    height, width = image_gs.shape[0:2]\n",
    "    image_binary = np.ndarray((height, width), dtype=np.uint8)\n",
    "    ret, image_bin = cv2.threshold(image_gs, 28, 255, cv2.THRESH_BINARY)\n",
    "    return image_bin\n",
    "\n",
    "def adaptive_treshold(image):\n",
    "    return cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,21,4)\n",
    "\n",
    "def display_image(image, color=False):\n",
    "    plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    if color:\n",
    "        plt.imshow(image)\n",
    "    else:\n",
    "        plt.imshow(image,'gray')\n",
    "        \n",
    "def invert(image):\n",
    "    return 255-image\n",
    "\n",
    "def dilate(image, iterations, kernel=kernel_size):\n",
    "    return cv2.dilate(image, kernel, iterations=iterations)\n",
    "\n",
    "def erode(image, iterations, kernel=kernel_size):\n",
    "    return cv2.erode(image, kernel, iterations=iterations)\n",
    "\n",
    "def closing(image, dilate_iterations, erode_iterations, dilate_kernel=kernel_size, erode_kernel=kernel_size):\n",
    "    return erode(dilate(image, dilate_iterations, dilate_kernel), erode_iterations, erode_kernel)\n",
    "\n",
    "def opening(image, dilate_iterations, erode_iterations, dilate_kernel=kernel_size, erode_kernel=kernel_size):\n",
    "    return dilate(erode(image, erode_iterations, erode_kernel), dilate_iterations, dilate_kernel)\n",
    "\n",
    "def crop_image(image, from_x, to_x, from_y, to_y):\n",
    "    return image[from_x:to_x, from_y:to_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_cross(y, yy):\n",
    "    return abs(yy -y ) < 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path):\n",
    "    \n",
    "    number_of_people = 0\n",
    "    \n",
    "    # crossing line y cordinate\n",
    "    line_y = 250\n",
    "    \n",
    "    # read video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    ret_val, frame = cap.read()\n",
    "\n",
    "    frame_gray = image_gray(frame)\n",
    "\n",
    "    current_frame = frame\n",
    "    \n",
    "    counter = -1\n",
    "    \n",
    "    while True:\n",
    "        success, next_frame = cap.read()\n",
    "        \n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "        # process every fifth frame\n",
    "        if counter != 5:\n",
    "            continue\n",
    "        \n",
    "        counter = 0\n",
    "        \n",
    "        current_frame_gray = image_gray(current_frame)\n",
    "        next_frame_gray = image_gray(next_frame)\n",
    "        \n",
    "        current_frame = next_frame\n",
    "        \n",
    "        # difference between current and previous frame\n",
    "        diff = cv2.absdiff(current_frame_gray, next_frame_gray)\n",
    "\n",
    "        diff_bin = adaptive_treshold(diff)\n",
    "        \n",
    "        diff_bin = closing(diff_bin, 1, 3)\n",
    "        \n",
    "        contours, _ = cv2.findContours(diff_bin, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        for contour in contours:\n",
    "            (x,y), (width, height), _ = cv2.minAreaRect(contour)\n",
    "\n",
    "            if not 10 < width < 70 or not 10 < height < 70:\n",
    "                continue\n",
    "                \n",
    "            if detect_cross(y, line_y):\n",
    "                number_of_people += 1\n",
    "    cap.release()\n",
    "    return number_of_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people:  4\n",
      "Number of people:  29\n",
      "Number of people:  18\n",
      "Number of people:  28\n",
      "Number of people:  15\n",
      "Number of people:  30\n",
      "Number of people:  27\n",
      "Number of people:  21\n",
      "Number of people:  9\n",
      "Number of people:  15\n",
      "\n",
      "MAE:  2.8\n"
     ]
    }
   ],
   "source": [
    " videos = [\"video1.mp4\", \"video2.mp4\", \"video3.mp4\", \"video4.mp4\", \"video5.mp4\", \"video6.mp4\",\n",
    "           \"video7.mp4\", \"video8.mp4\", \"video9.mp4\", \"video10.mp4\"]\n",
    "\n",
    "number_of_people = [4, 24, 17, 23, 17, 27, 29, 22, 10, 23]\n",
    "err_sum = 0\n",
    "\n",
    "for i, video in enumerate(videos):\n",
    "    people_counted = process_video(\"data/\" + video)\n",
    "    print (\"Number of people: \", people_counted)\n",
    "    err = abs(number_of_people[i] - people_counted)\n",
    "    err_sum += err\n",
    "    \n",
    "print (\"\\nMAE: \", err_sum / len(videos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
